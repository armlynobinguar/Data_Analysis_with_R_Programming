library(rvest)
library(dplyr)

scraper <- function(url, selector, output = "text", all_nodes = TRUE) {
    
    # Loading the web page content
    content <- read_html(url)

    # Getting one or all nodes
    if (all_nodes) {
        nodes <- content %>% 
            html_nodes(selector)
    } else {
        nodes <- content %>% 
            html_node(selector)
    }
    
    # Outputting text, table, attributes, or attribute
    
    if (output == "text") {
        answer <- nodes %>% html_text()
    } else if (output == "table") {
        answer <- nodes %>% html_table()
    } else if (output == "attrs") {
        answer <- nodes %>% html_attrs()
    } else {
        answer <- nodes %>% html_attr(output)
    }
    
   # Returning the output
   answer 
}

scraper(url = "http://dataquestio.github.io/web-scraping-pages/2014_super_bowl.html", 
        selector = "table tr:nth-child(3) td")


belgium_temperatures_text <- scraper(url = "http://dataquestio.github.io/web-scraping-pages/Brussels_Belgium_Weather_AccuWeather.html",
                                     selector = ".half-day-card-header .temperature")
belgium_temperatures <- readr::parse_number(belgium_temperatures_text)

wiki_infobox <- scraper(url = "http://dataquestio.github.io/web-scraping-pages/Earth-Wiki.html", 
                        selector = ".infobox")
earth_mean_radius_matches <- stringr::str_match(wiki_infobox, "Mean radius(\\d+\\.\\d+)\\s*km")
earth_mean_radius <- as.numeric(earth_mean_radius_matches[,2])

accepted_message <- scraper(url = "http://dataquestio.github.io/web-scraping-pages/WebSraping-ethics-SE.html", 
                               selector = ".accepted-answer .s-prose", 
                               all_nodes = F)

accepted_message_author <- scraper(url = "http://dataquestio.github.io/web-scraping-pages/WebSraping-ethics-SE.html", 
                                      selector = ".accepted-answer .user-details a", 
                                      all_nodes = F)
                                      
    world_population_df <- scraper(url = "http://dataquestio.github.io/web-scraping-pages/Worldometer-Population.html", 
                               selector = "table", 
                               output = "table", 
                               all_nodes = F)

world_population_df_1950_2019 <- world_population_df %>% 
  mutate(YearlyChange = readr::parse_number(YearlyChange) ) %>%
  filter(Year >= 1950 & Year < 2020)

library(ggplot2)
ggplot(data = world_population_df_1950_2019,
       aes(x = Year, y = YearlyChange, group = 1)) + 
  geom_line() + 
  geom_point(size = 2) +
  theme_bw() +
  theme() +  ylab("Yearly Change")
